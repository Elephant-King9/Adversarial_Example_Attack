import torch
import time
from torchvision import transforms

class attack_IFGSM:
    def __init__(self, model, val_DataLoader, config):
        self.model = model
        self.device = config.device
        self.val_DataLoader = val_DataLoader
        self.alpha = config.alpha
        self.iters = config.iters

    # def test(self, eps):
    #     accuracy = 0
    #     adv_examples = []
    #     start_time = time.time()
    #     for img, label in self.val_DataLoader:
    #         img, label = img.to(self.device), label.to(self.device)
    #         img.requires_grad = True
    #         output = self.model(img)
    #
    #         init_pred = output.argmax(dim=1, keepdim=True)
    #         if init_pred.item() != label.item():
    #             continue
    #
    #         perturbed_data = self.attack(img, eps, label)
    #
    #         perturbed_data_normalized = transforms.Normalize((0.1307,), (0.3081,))(perturbed_data)
    #         output = self.model(perturbed_data_normalized)
    #
    #         final_pred = output.argmax(dim=1, keepdim=True)
    #         if final_pred.item() == label.item():
    #             accuracy += 1
    #             if eps == 0 and len(adv_examples) < 5:
    #                 adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
    #                 adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
    #         else:
    #             if len(adv_examples) < 5:
    #                 adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
    #                 adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
    #
    #     final_acc = accuracy / float(len(self.val_DataLoader))
    #     end_time = time.time()
    #     print(f"Epsilon: {eps}\tTest Accuracy = {accuracy} / {len(self.val_DataLoader)} = {final_acc}, Time = {end_time - start_time}")
    #     return final_acc, adv_examples

    import torch

    def attack(self, image, epsilon, data_grad):
        """
        Perform IFGSM attack
        :param image: è¾“å…¥å›¾ç‰‡
        :param epsilon: ðœ€è¶…å‚æ•°
        :param data_grad: æ¢¯åº¦
        :return: ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬
        """
        # å…‹éš†åŽŸå§‹å›¾åƒï¼Œä»¥å…ä¿®æ”¹åŽŸå›¾
        perturbed_image = image.clone().detach().to(self.device)

        # åå‘å½’ä¸€åŒ–å¤„ç†
        denorm = transforms.Normalize((0.1307,), (0.3081,))  # MNISTæ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®
        image_denorm = denorm(image)

        for _ in range(self.iters):
            perturbed_image.requires_grad = True
            output = self.model(perturbed_image)
            loss = torch.nn.functional.nll_loss(output, label)
            self.model.zero_grad()
            loss.backward()
            data_grad = perturbed_image.grad.data
            sign_data_grad = data_grad.sign()
            perturbed_image = image_denorm + self.alpha * sign_data_grad
            # å°†å¯¹æŠ—æ ·æœ¬çš„æ‰°åŠ¨é™åˆ¶åœ¨åŽŸå§‹å›¾åƒçš„epsilonèŒƒå›´å†…
            perturbed_image = torch.clamp(perturbed_image, image - epsilon, image + epsilon)
            # å°†ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬çš„å€¼é™åˆ¶åœ¨0åˆ°1ä¹‹é—´
            perturbed_image = torch.clamp(perturbed_image, 0, 1)

        return perturbed_image

